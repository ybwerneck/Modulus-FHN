{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28391227-7b25-4080-a670-584a1d421101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T04:49:50.740453Z",
     "iopub.status.busy": "2023-03-04T04:49:50.740168Z",
     "iopub.status.idle": "2023-03-04T04:49:50.750335Z",
     "shell.execute_reply": "2023-03-04T04:49:50.749564Z",
     "shell.execute_reply.started": "2023-03-04T04:49:50.740390Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conf/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conf/config.yaml\n",
    "# Arch\t                        Start Lr\tMax Steps\tDecay Steps\n",
    "# FullyConnectedArch\t        1.00E-03\t1500000\t        15000\t   \n",
    "# FourierNetArch                1.00E-03\t400000\t        7500\t   \n",
    "# ModifiedFourierNetArch \t1.00E-03\t400000\t        7500\t   \n",
    "# SirenArch                     2.00E-05\t500000\t        5000\t   \n",
    "# DGMArch                       1.00E-03        1500000         15000           \n",
    "\n",
    "# WARNING: Setting \"exact_continuity\" to true or setting the arch\n",
    "# as \"ModifiedFourierNetArch\" increases the memory requirements of the \n",
    "# problem. Batchsizes may need to be reduced for such cases.  \n",
    "\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: exponential_lr \n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "jit: false\n",
    "\n",
    "\n",
    "training:\n",
    "  rec_results_freq : 1000\n",
    "  rec_constraint_freq: 1000\n",
    "  max_steps : 3000\n",
    "\n",
    "batch_size:\n",
    "  initial_condition: 4096\n",
    "  interior: 4096\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa46a6-e84a-475c-a68b-ba58135cc55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0123240d-382f-4848-bbd1-83b804e4d626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T04:49:50.930320Z",
     "iopub.status.busy": "2023-03-04T04:49:50.929881Z",
     "iopub.status.idle": "2023-03-04T04:49:50.942240Z",
     "shell.execute_reply": "2023-03-04T04:49:50.941421Z",
     "shell.execute_reply.started": "2023-03-04T04:49:50.930292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fhn2eqtwboth3C.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fhn2eqtwboth3C.py\n",
    "from modulus.models.fully_connected import FullyConnectedArch\n",
    "from modulus.models.fourier_net import FourierNetArch\n",
    "from modulus.models.siren import SirenArch\n",
    "from modulus.models.modified_fourier_net import ModifiedFourierNetArch\n",
    "from modulus.models.dgm import DGMArch\n",
    "\n",
    "from sympy import Symbol, Eq\n",
    "from sympy import Symbol, Function, Number\n",
    "from modulus.eq.pde import PDE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import modulus\n",
    "from modulus.hydra import instantiate_arch, ModulusConfig\n",
    "from modulus.solver import Solver\n",
    "from modulus.domain import Domain\n",
    "from modulus.geometry.primitives_1d import Point1D\n",
    "from modulus.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "from modulus.domain.validator import PointwiseValidator\n",
    "from modulus.key import Key\n",
    "from modulus.node import Node\n",
    "from modulus.eq.pde import PDE\n",
    "from modulus.geometry import Parameterization\n",
    "from sympy import Symbol, Eq, Abs, tanh, Or, And\n",
    "from modulus.utils.io import (\n",
    "    csv_to_dict,\n",
    "    ValidatorPlotter,\n",
    "    InferencerPlotter,\n",
    ")\n",
    "from modulus.solver import SequentialSolver\n",
    "\n",
    "from modulus.models.deeponet import DeepONetArch\n",
    "from modulus.domain.constraint.continuous import DeepONetConstraint\n",
    "from modulus.models.moving_time_window import MovingTimeWindowArch\n",
    "from modulus.domain.monitor import Monitor\n",
    "from modulus.domain.constraint import Constraint\n",
    "from modulus.graph import Graph\n",
    "from modulus.key import Key\n",
    "from modulus.constants import TF_SUMMARY\n",
    "from modulus.distributed import DistributedManager\n",
    "from modulus.utils.io import dict_to_csv, csv_to_dict\n",
    "from modulus.domain.inferencer.pointwise import PointwiseInferencer as PointwiseInferencer\n",
    "from modulus.loss.loss import CausalLossNorm\n",
    "\n",
    "class MONI(Monitor):\n",
    "    \"\"\"\n",
    "    Pointwise Inferencer that allows inferencing on pointwise data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    invar : Dict[str, np.ndarray (N, 1)]\n",
    "        Dictionary of numpy arrays as input.\n",
    "    output_names : List[str]\n",
    "        List of outputs needed for metric.\n",
    "    metrics : Dict[str, Callable]\n",
    "        Dictionary of pytorch functions whose input is a dictionary\n",
    "        torch tensors whose keys are the `output_names`. The keys\n",
    "        to `metrics` will be used to label the metrics in tensorboard/csv outputs.\n",
    "    nodes : List[Node]\n",
    "        List of Modulus Nodes to unroll graph with.\n",
    "    requires_grad : bool = False\n",
    "        If automatic differentiation is needed for computing results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, invar, output_names, metrics, nodes, requires_grad=False):\n",
    "\n",
    "        # construct model from nodes\n",
    "        self.requires_grad = requires_grad\n",
    "        self.model = Graph(\n",
    "            nodes, Key.convert_list(invar.keys()), Key.convert_list(output_names)\n",
    "        )\n",
    "        self.manager = DistributedManager()\n",
    "        self.device = self.manager.device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # set metrics\n",
    "        self.metrics = metrics\n",
    "        self.monitor_outvar_store = {}\n",
    "\n",
    "        # set invar\n",
    "        self.invar = Constraint._set_device(invar, device=self.device)\n",
    "\n",
    "    def save_results(self, name, writer, step, data_dir):\n",
    "        plt.clf()\n",
    "        # run forward inference\n",
    "        invar = Constraint._set_device(\n",
    "            self.invar, device=self.device, requires_grad=self.requires_grad\n",
    "        )\n",
    "        outvar = self.model(invar)\n",
    "        metrics = {key: func({**invar, **outvar}) for key, func in self.metrics.items()}\n",
    "        t=metrics[\"t\"].detach().cpu().numpy()\n",
    "        x1=metrics[\"x1\"].detach().cpu().numpy()\n",
    "        odex1=metrics[\"ode_x1\"].detach().cpu().numpy()\n",
    "        plt.scatter(t,x1)\n",
    "        \n",
    "        plt.savefig(data_dir+\"x1s\"+str(step)+\".png\")\n",
    "        plt.clf()\n",
    "        plt.scatter(t,odex1)\n",
    "       # print(t)\n",
    "\n",
    "        \n",
    "        plt.savefig(data_dir+\"ode_x1s\"+str(step)+\".png\")\n",
    "       \n",
    "        return metrics\n",
    "\n",
    "    \n",
    "t_max = 10.0\n",
    "n_w=10\n",
    "t_w= t_max/n_w\n",
    "def generateExactSolution(t,dt,x0,w0,rate,P,begin,end):\n",
    "    \n",
    "    \n",
    "    n2=int(t/(dt))+2\n",
    "    n = int((end-begin)/(dt*rate))\n",
    "    Sol=np.zeros((n,3))\n",
    "  \n",
    "    Sol2=np.zeros((n2,2))\n",
    "    Sol2[0]=x0,w0\n",
    "    T=0\n",
    "    k=0\n",
    "    while(k<n2-1):\n",
    "        x,w=Sol2[k]\n",
    "        Sol2[k+1]=P*(x*(x-0.4)*(1-x)-w)*dt+  x, 0.5*(x*0.2-0.8*w)*dt +w\n",
    " \n",
    "        if ((k*dt==begin or ((k+1)%rate == 0 and k*dt>=begin and k*dt<=end))and T<n):\n",
    "          \n",
    "           \n",
    "            Sol[T] = Sol2[k][0],Sol2[k][1] , k*dt\n",
    "            T=T+1\n",
    "        \n",
    "        k=k+1\n",
    "        if(k*dt > end):\n",
    "            break\n",
    "    return Sol\n",
    "\n",
    "def generateValidator(w_i,nodes):\n",
    "\n",
    "    \n",
    "    \n",
    "    T=np.empty([0])\n",
    "    K=np.empty([0])\n",
    "    SOLs=np.empty([0])\n",
    "    SOLw=np.empty([0])\n",
    "    V=np.empty([0])\n",
    "    U=np.empty([0])\n",
    "    krange= [(2 + 0.09*i*12) for i in range(0,10)]\n",
    "    urange= [(0 + 0.1*i*1) for i in range(0,10)]\n",
    "\n",
    "    deltaT = 0.01\n",
    "    \n",
    "    rate=5\n",
    "    for UR in urange: \n",
    "        for KR in krange:\n",
    "            for VR in vrange:\n",
    "                begin=w_i* t_w\n",
    "                end=begin + t_w\n",
    "                sol=generateExactSolution(t_max,deltaT,UR,VR,rate,KR,begin,end)\n",
    "            \n",
    "                T=np.append(T,sol.T[2] - begin)\n",
    "                K = np.append(K,np.full_like (sol.T[2],KR))\n",
    "                U = np.append(U,np.full_like (sol.T[2],UR))\n",
    "\n",
    "                V= np.append(V,np.full_like(sol.T[2],VR))\n",
    "                SOLs=np.append(SOLs,sol.T[0])\n",
    "                SOLw=np.append(SOLw,sol.T[1])\n",
    "\n",
    "\n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "\n",
    "\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "    u = np.expand_dims(U, axis=-1)\n",
    "    \n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "\n",
    "    \n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "   \n",
    "    v= np.expand_dims(V,axis=-1)\n",
    "    print(t,\"val set de \",begin,\"a \", end)\n",
    "\n",
    "    \n",
    "    invar_numpy = {\"t\": t,\"K\":k,\"V\":v,\"U\":u}\n",
    "    outvar_numpy = {\n",
    "        \"x1\": Solx,\n",
    "        \"w\":Solw\n",
    "    }\n",
    "   \n",
    "    validator = PointwiseValidator(\n",
    "        nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy, batch_size=1024,plotter=None\n",
    "    )\n",
    "    return validator\n",
    "\n",
    "def generateDataC(w_i,nodes):\n",
    "\n",
    "    \n",
    "    \n",
    "    T=np.empty([0])\n",
    "    K=np.empty([0])\n",
    "    SOLs=np.empty([0])\n",
    "    SOLw=np.empty([0])\n",
    "    V=np.empty([0])\n",
    "    U=np.empty([0])\n",
    "    krange= [(2 + 0.05*i*12) for i in range(0,20)]\n",
    "    vrange= [(0 + 0.05*i*.12) for i in range(0,20)]\n",
    "    urange= [(0 + 0.05*i*1) for i in range(0,20)]\n",
    "\n",
    "    deltaT = 0.01\n",
    "    \n",
    "    rate=1\n",
    "    for UR in urange: \n",
    "        for KR in krange:\n",
    "            for VR in vrange:\n",
    "                begin=w_i* t_w\n",
    "                end=begin + t_w\n",
    "                sol=generateExactSolution(t_max,deltaT,UR,VR,rate,KR,begin,end)\n",
    "\n",
    "                T=np.append(T,sol.T[2] - begin)\n",
    "                K = np.append(K,np.full_like (sol.T[2],KR))\n",
    "                U = np.append(U,np.full_like (sol.T[2],UR))\n",
    "\n",
    "                V= np.append(V,np.full_like(sol.T[2],VR))\n",
    "                SOLs=np.append(SOLs,sol.T[0])\n",
    "                SOLw=np.append(SOLw,sol.T[1])\n",
    "    \n",
    "    \n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "\n",
    "\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "    u = np.expand_dims(U, axis=-1)\n",
    "    \n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "\n",
    "    \n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "   \n",
    "    v= np.expand_dims(V,axis=-1)\n",
    "    print(t,\"val set de \",begin,\"a \", end)\n",
    "\n",
    "    \n",
    "    invar_numpy = {\"t\": t,\"K\":k,\"V\":v,\"U\":u}\n",
    "    outvar_numpy = {\n",
    "        \"x1\": Solx,\n",
    "        \"w\":Solw\n",
    "    }\n",
    "    print(np.shape(Solx),np.shape(Solw),np.shape(t),np.shape(k),np.shape(v))\n",
    "    data = DeepONetConstraint.from_numpy(\n",
    "        nodes=nodes,\n",
    "        invar=invar_numpy,\n",
    "        outvar=outvar_numpy,\n",
    "        batch_size=12000,\n",
    "        lambda_weighting=None\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "class SpringMass(PDE):\n",
    "    name = \"SpringMass\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        t = Symbol(\"t\")\n",
    "        K = Symbol(\"K\")\n",
    "       \n",
    "        input_variables = {\"t\": t,\"K\":K}\n",
    "\n",
    "        x = Function(\"x1\")(*input_variables)\n",
    "        w= Function(\"w\")(*input_variables)\n",
    "        self.equations = {}\n",
    "        self.equations[\"ode_x1\"] =K*(x*(x-0.4)*(1-x)-w) -x.diff(t)\n",
    "        self.equations[\"ode_w\"]  =0.5*(x*0.2-0.8*w) -w.diff(t)\n",
    "        \n",
    "@modulus.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    \n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass()\n",
    "    sm.pprint()\n",
    "    #sm_net = FullyConnectedArch(\n",
    "    #    input_keys=[Key(\"t\"), Key(\"K\")],\n",
    "    #    output_keys=[Key(\"x1\")],\n",
    "    #)\n",
    "    #nodes = sm.make_nodes() + [\n",
    "    #    sm_net.make_node(name=\"network\")\n",
    "    #]\n",
    "\n",
    "\n",
    "    \n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass()\n",
    "    sm.pprint()\n",
    "    #sm_net = FullyConnectedArch(\n",
    "    #    input_keys=[Key(\"t\"), Key(\"K\")],\n",
    "    #    output_keys=[Key(\"x1\")],\n",
    "    #)\n",
    "    #nodes = sm.make_nodes() + [\n",
    "    #    sm_net.make_node(name=\"network\")\n",
    "    #]\n",
    "\n",
    "    \n",
    "    \n",
    "    flow_net = FullyConnectedArch(\n",
    "            input_keys=[Key(\"t\"), Key(\"U\"),Key(\"V\"),Key(\"K\") ],\n",
    "            output_keys=[Key(\"x1\"),Key(\"w\")],\n",
    "            layer_size=400,\n",
    "            nr_layers=12,\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    time_window_net = MovingTimeWindowArch(flow_net, t_w)\n",
    "\n",
    "    nodes = sm.make_nodes() +[time_window_net.make_node(name=\"network\")]\n",
    "\n",
    "\n",
    "    for node in nodes:\n",
    "        print(node.__str__())\n",
    "   \n",
    "    # add constraints to solver\n",
    "    # make geometry\n",
    "    geo = Point1D(0)\n",
    "    \n",
    "    t_symbol = Symbol(\"t\")\n",
    "    x_symbol = Symbol(\"x1\")\n",
    "    k_symbol= Symbol(\"K\")\n",
    "    v_symbol= Symbol(\"V\")\n",
    "    u_symbol= Symbol(\"U\")\n",
    "    \n",
    "    time_range = {t_symbol: (0,t_w )}\n",
    "    k_range= {k_symbol:(2,14)}\n",
    "    v_range= {v_symbol:(0,.12)}\n",
    "    u_range= {u_symbol:(0,1)}\n",
    "\n",
    "    tr = {t_symbol: (0, t_w)}\n",
    "\n",
    "    # make domain\n",
    "        # make initial condition domain\n",
    "    ic_domain = Domain(\"initial_conditions\")\n",
    "\n",
    "  \n",
    "    # initial conditions\n",
    "    IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1\": u_symbol,\"w\":v_symbol},\n",
    "        batch_size=2000,\n",
    "        parameterization={**{t_symbol:0},**k_range,**v_range,**u_range},\n",
    "        lambda_weighting={\n",
    "            \"x1\": 100,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"w\": 100 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        \n",
    "        \n",
    "        quasirandom=True,\n",
    "    )\n",
    "\n",
    "    ic_domain.add_constraint(IC, name=\"IC\")\n",
    "    \n",
    "        # solve over given time period\n",
    "    interior = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=4000,\n",
    "        parameterization={**tr,**k_range,**v_range,**u_range},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 1,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\":1 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        loss=CausalLossNorm(eps=1.0),\n",
    "        quasirandom=True,\n",
    "    )\n",
    "    ic_domain.add_constraint(interior, name=\"interior\")\n",
    "    \n",
    "    \n",
    "       # solve over given time period\n",
    "    interior2 = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=5000,\n",
    "        parameterization={**tr,**{k_symbol:(10,14)},**{v_symbol:(0,.1)},**{u_symbol:(0.35,0.55)}},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\":1,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\": 1 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "    )\n",
    "    ic_domain.add_constraint(interior2, name=\"interiorTr\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    domains=[]\n",
    "    for i in range(1,n_w):\n",
    "\n",
    "        # make moving window domain\n",
    "        window_domain = Domain(\"window\"+str(i))\n",
    "\n",
    "        # solve over given time period\n",
    "        interior1 = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=4000,\n",
    "        parameterization={**tr,**k_range,**v_range,**u_range},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 1,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\": 1 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        loss=CausalLossNorm(eps=1.0),\n",
    "        quasirandom=True,\n",
    "\n",
    "        )\n",
    "        interior2 = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=5000,\n",
    "        parameterization={**tr,**{k_symbol:(10,14)},**{v_symbol:(0,.1)},**{u_symbol:(0.35,0.45)}},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 1,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\":  1 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1_prev_step_diff\":0,\"w_prev_step_diff\":0},\n",
    "        batch_size=4000,\n",
    "        parameterization={**{t_symbol:0},**k_range,**v_range,**u_range},\n",
    "        lambda_weighting={\n",
    "            \"x1_prev_step_diff\": 1000,\n",
    "            \"w_prev_step_diff\": 1000\n",
    "        },\n",
    "        \n",
    "        quasirandom=True,\n",
    "    )\n",
    "        \n",
    "    \n",
    "        \n",
    "        window_domain.add_constraint(IC, name=\"IC\")\n",
    "        window_domain.add_constraint(interior1, \"interior\")\n",
    "        window_domain.add_constraint(interior2, \"interiorTr\")\n",
    "\n",
    "        domains.append(window_domain)\n",
    "    \n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    dom=[]\n",
    "    dom.append((1,ic_domain))\n",
    "\n",
    "    for domain in domains:\n",
    "        dom.append((1,domain))\n",
    "    print(cfg)\n",
    "    # make solver\n",
    "    #slv = Solver(cfg, domain)\n",
    "    #print(domains)\n",
    "    i=0\n",
    "    for a,d in dom:\n",
    "        print(d)\n",
    "        print(d.name)\n",
    "        d.add_validator(generateValidator(i,nodes))\n",
    "        d.add_constraint(generateDataC(i,nodes),\"data\")\n",
    "\n",
    "        i=i+1\n",
    "    \n",
    "      \n",
    "    slv = SequentialSolver(\n",
    "        cfg,\n",
    "        dom,\n",
    "        custom_update_operation=time_window_net.move_window,\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c040c0-2585-4135-a686-b9719ab67fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T04:49:50.944531Z",
     "iopub.status.busy": "2023-03-04T04:49:50.943664Z",
     "iopub.status.idle": "2023-03-04T04:50:32.873649Z",
     "shell.execute_reply": "2023-03-04T04:50:32.872725Z",
     "shell.execute_reply.started": "2023-03-04T04:49:50.944504Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:49:57] - JitManager: {'_enabled': False, '_arch_mode': <JitArchMode.ONLY_ACTIVATION: 1>, '_use_nvfuser': True, '_autograd_nodes': False}\n",
      "[04:49:57] - GraphManager: {'_func_arch': False, '_debug': False, '_func_arch_allow_partial_hessian': True}\n",
      "ode_x1: K*((1 - x1)*(x1 - 0.4)*x1 - w) - x1__t\n",
      "ode_w: -0.4*w + 0.1*x1 - w__t\n",
      "ode_x1: K*((1 - x1)*(x1 - 0.4)*x1 - w) - x1__t\n",
      "ode_w: -0.4*w + 0.1*x1 - w__t\n",
      "node: Sympy Node: ode_x1\n",
      "evaluate: SympyToTorch\n",
      "inputs: [K, w, x1]\n",
      "derivatives: [x1__t]\n",
      "outputs: [ode_x1]\n",
      "optimize: False\n",
      "node: Sympy Node: ode_w\n",
      "evaluate: SympyToTorch\n",
      "inputs: [w, x1]\n",
      "derivatives: [w__t]\n",
      "outputs: [ode_w]\n",
      "optimize: False\n",
      "node: Arch Node: network\n",
      "evaluate: MovingTimeWindowArch\n",
      "inputs: [t, U, V, K]\n",
      "derivatives: []\n",
      "outputs: [x1, w, x1_prev_step, w_prev_step, x1_prev_step_diff, w_prev_step_diff]\n",
      "optimize: True\n",
      "{'training': {'max_steps': 3000, 'grad_agg_freq': 1, 'rec_results_freq': 1000, 'rec_validation_freq': '${training.rec_results_freq}', 'rec_inference_freq': '${training.rec_results_freq}', 'rec_monitor_freq': '${training.rec_results_freq}', 'rec_constraint_freq': 1000, 'save_network_freq': 1000, 'print_stats_freq': 100, 'summary_freq': 1000, 'amp': False, 'amp_dtype': 'float16', 'ntk': {'use_ntk': False, 'save_name': None, 'run_freq': 1000}}, 'graph': {'func_arch': False, 'func_arch_allow_partial_hessian': True}, 'stop_criterion': {'metric': None, 'min_delta': None, 'patience': 50000, 'mode': 'min', 'freq': 1000, 'strict': False}, 'profiler': {'profile': False, 'start_step': 0, 'end_step': 100, 'name': 'nvtx'}, 'network_dir': '.', 'initialization_network_dir': '', 'save_filetypes': 'vtk', 'summary_histograms': False, 'jit': False, 'jit_use_nvfuser': True, 'jit_arch_mode': 'only_activation', 'jit_autograd_nodes': False, 'cuda_graphs': True, 'cuda_graph_warmup': 20, 'find_unused_parameters': False, 'broadcast_buffers': False, 'device': '', 'debug': False, 'run_mode': 'train', 'arch': {'fully_connected': {'arch_type': 'fully_connected', 'input_keys': '???', 'output_keys': '???', 'detach_keys': '???', 'scaling': None, 'layer_size': 512, 'nr_layers': 6, 'skip_connections': False, 'activation_fn': 'silu', 'adaptive_activations': False, 'weight_norm': True}}, 'models': '???', 'loss': {'_target_': 'modulus.loss.aggregator.Sum', 'weights': None}, 'optimizer': {'_params_': {'compute_gradients': 'adam_compute_gradients', 'apply_gradients': 'adam_apply_gradients'}, '_target_': 'torch.optim.Adam', 'lr': 0.001, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ExponentialLR', 'gamma': 0.99998718}, 'batch_size': {'initial_condition': 4096, 'interior': 4096}, 'custom': '???'}\n",
      "<modulus.domain.domain.Domain object at 0x7f1dde72d5b0>\n",
      "initial_conditions\n",
      "Error executing job with overrides: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/final/fhn2eqtwboth3C.py\", line 479, in run\n",
      "    d.add_validator(generateValidator(i,nodes))\n",
      "  File \"/home/jovyan/final/fhn2eqtwboth3C.py\", line 157, in generateValidator\n",
      "    for VR in vrange:\n",
      "NameError: name 'vrange' is not defined\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "!rm -r outputs/fhn2eqtwboth3C || true ##se não limpar o output ele aproveita o treinamento, mesmo se mudar o modelo\n",
    "!python fhn2eqtwboth3C.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ab5b4c-2930-4c71-8c1f-83b019197e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T04:50:32.874979Z",
     "iopub.status.busy": "2023-03-04T04:50:32.874718Z",
     "iopub.status.idle": "2023-03-04T04:50:34.464804Z",
     "shell.execute_reply": "2023-03-04T04:50:34.463671Z",
     "shell.execute_reply.started": "2023-03-04T04:50:32.874949Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/fhn2eqtw/window_0009/validators/validator.vtp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m (np\u001b[38;5;241m.\u001b[39mshape(out_t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    102\u001b[0m     call(invar,out_t,out)\n\u001b[0;32m--> 105\u001b[0m plot(base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/fhn2eqtw/window_0009/validators/validator.vtp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [4], line 82\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(base_dir)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/fhnw/window0/validators/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(data\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39marr_0)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     84\u001b[0m     invar\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     85\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m:data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m:data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     86\u001b[0m           }\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/numpy/lib/npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 417\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    418\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/fhn2eqtw/window_0009/validators/validator.vtp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "def find(list_to_check, item_to_find):\n",
    "    return [idx for idx, value in enumerate(list_to_check) if value == item_to_find]\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_2D( size, invar, *outvars):\n",
    "        \"Interpolate 2D outvar solutions onto a regular mesh\"\n",
    "\n",
    "        print(len(invar))\n",
    "        assert len(invar) == 2\n",
    "\n",
    "        # define regular mesh to interpolate onto\n",
    "        xs = [invar[k][:, 0] for k in invar]\n",
    "        extent = (xs[0].min(), xs[0].max(), xs[1].min(), xs[1].max())\n",
    "        xyi = np.meshgrid(\n",
    "            np.linspace(extent[0], extent[1], size),\n",
    "            np.linspace(extent[2], extent[3], size),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "\n",
    "        # interpolate outvars onto mesh\n",
    "        outvars_interp = []\n",
    "        for outvar in outvars:\n",
    "            outvar_interp = {}\n",
    "            for k in outvar:\n",
    "                outvar_interp[k] = scipy.interpolate.griddata(\n",
    "                    (xs[0], xs[1]), outvar[k][:, 0], tuple(xyi)\n",
    "                )\n",
    "            outvars_interp.append(outvar_interp)\n",
    "\n",
    "        return [extent] + outvars_interp\n",
    "\n",
    "\n",
    "def call(invar, true_outvar, pred_outvar):\n",
    "\n",
    "\n",
    "\n",
    "        # interpolate 2D data onto grid\n",
    "        print(len(invar))\n",
    "        extent, true_outvar, pred_outvar = interpolate_2D(\n",
    "                200, invar, true_outvar, pred_outvar\n",
    "            )\n",
    "        ndim=2\n",
    "        # make plots\n",
    "        dims = list(invar.keys())\n",
    "        fs = []\n",
    "        for k in pred_outvar:\n",
    "            f = plt.figure(figsize=(3 * 5, 4), dpi=100)\n",
    "            for i, (o, tag) in enumerate(\n",
    "                zip(\n",
    "                    [true_outvar[k], pred_outvar[k], ((true_outvar[k] - pred_outvar[k])**2)**(0.5) ],\n",
    "                    [\"true\", \"pred\", \"diff\"],\n",
    "                )\n",
    "            ):\n",
    "                if (tag==\"diff\"):\n",
    "                    print(\"max diff\",np.max(o))\n",
    "                plt.subplot(1, 3, 1 + i)\n",
    "                if ndim == 1:\n",
    "                    plt.plot(invar[dims[0]][:, 0], o[:, 0])\n",
    "                    plt.xlabel(dims[0])\n",
    "                elif ndim == 2:\n",
    "                    plt.imshow(o.T, origin=\"lower\", extent=extent)\n",
    "                    \n",
    "                    plt.xlabel(dims[0])\n",
    "                    plt.ylabel(dims[1])\n",
    "                    if(tag==\"diff\"):\n",
    "                       \n",
    "                        plt.clim(0,0.6)\n",
    "                    else :\n",
    "                        plt.clim(0,1)\n",
    "                    plt.colorbar()\n",
    "                plt.title(f\"{k}_{tag}\")\n",
    "            plt.tight_layout()\n",
    "            fs.append((f, k))\n",
    "     \n",
    "def plot(base_dir = \"outputs/fhnw/window0/validators/\"):\n",
    "    \n",
    "\n",
    "    data = np.load(base_dir, allow_pickle=True)\n",
    "    data = np.atleast_1d(data.f.arr_0)[0]\n",
    "    invar={\n",
    "           \"t\":data[\"t\"],\"K\":data[\"K\"]*15\n",
    "          }\n",
    "    print(len(invar))\n",
    "    out={\"x1\":data[\"pred_x1\"],\n",
    "         }\n",
    "    out_t={\"x1\":data[\"true_x1\"],\n",
    "          }\n",
    "    \n",
    "    print (np.shape(out_t[\"x1\"]))\n",
    "    call(invar,out_t,out)\n",
    "    print(len(invar))\n",
    "    out={\"w\":data[\"pred_w\"],\n",
    "         }\n",
    "    out_t={\"w\":data[\"true_w\"],\n",
    "          }\n",
    "    \n",
    "    print (np.shape(out_t[\"w\"]))\n",
    "    call(invar,out_t,out)\n",
    "    \n",
    "    \n",
    "plot(base_dir = \"outputs/fhn2eqtw/window_0009/validators/validator.vtp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d5a3e-924c-4f8d-a3b4-310ecaac73d4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-04T04:50:34.465965Z",
     "iopub.status.idle": "2023-03-04T04:50:34.466303Z",
     "shell.execute_reply": "2023-03-04T04:50:34.466154Z",
     "shell.execute_reply.started": "2023-03-04T04:50:34.466136Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find(list_to_check, item_to_find):\n",
    "    return [idx for idx, value in enumerate(list_to_check) if value == item_to_find]\n",
    "\n",
    "base_dir =  \"outputs/fhn2eqtw/window1/validators/\"\n",
    "\n",
    "# plot in 1d\n",
    "data = np.load(base_dir + \"validator.npz\", allow_pickle=True)\n",
    "data = np.atleast_1d(data.f.arr_0)[0]\n",
    "\n",
    "ks=np.unique(data[\"K\"])\n",
    "t=np.unique(data[\"t\"])\n",
    "d=np.full_like(ks,0)\n",
    "\n",
    "\n",
    "for k in ks:\n",
    "    i=find(data[\"K\"],k)\n",
    "    #print(i)\n",
    "    x=data[\"true_x1\"][i]\n",
    "    pred=data[\"pred_x1\"][i]\n",
    "    w=data[\"true_w\"][i]\n",
    "    predw=data[\"pred_w\"][i]\n",
    "    d=np.mean(x-pred)\n",
    "    plt.ylim(-1,1.1)\n",
    "    plt.plot(t,x,\"o\",label=\"True ,k =\"+ str(k))\n",
    "    plt.plot(t,pred,label=\"Pred ,k =\"+ str(k))\n",
    "    plt.plot(t,w,\"o\",label=\"True w ,k =\"+ str(k))\n",
    "    print(predw[-1])\n",
    "    plt.plot(t,predw,label=\"Pred w ,k =\"+ str(k))\n",
    "   \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a4164-bbf2-4226-b9a8-9b4a47e67cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d47304-3202-4627-9ef6-d9412ef84342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd8c61-1454-445e-847b-907332aeab10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
